---
permalink: /
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


Hi! I am a Ph.D. candidate at the Univeristy of British Columbia (UBC) and the Vector Institute for AI advised by [Vered Shwartz](https://www.cs.ubc.ca/~vshwartz/) and [Raymond NG](https://www.cs.ubc.ca/people/raymond-ng) in the [Natural Language Processing group](http://www.cs.ubc.ca/cs-research/lci/research-groups/natural-language-processing/). I frequently collaborate with [Leonid Sigal](https://www.cs.ubc.ca/~lsigal/) in the Computer Vision group.

I work at the intersection of NLP and Computer Vision. Specifically, I evaluate and improve reasoning capabilities across multiple modalities (text, images, videos) - which are fundamental for safe and effective deployment in real-world applications such as embodied agents and AR/VR. Drawing inspiration from human cognition, I've worked on fundamental reasoning abilities including causal, counterfactual, and commonsense reasoning, as well as cultural and social norm understanding. 

Currently, I am investigating the robustness of Video-LLMs to unexpected scenarios. My recent work [Black Swan](https://blackswan.cs.ubc.ca/) evaluates models on how they explain and adapt in unpredictable video events. In my ongoing work [SPIKE](https://www.arxiv.org/pdf/2509.23433), I'm developing post-training methods inspired by Bayesian Theory of Mind that enable VLMs to revise their beliefs and become more resilient to novel scenarios.

I'd love to connect if you're interested in collaborating on multimodal reasoning or if you'd like to chat about PhD life at UBC.

